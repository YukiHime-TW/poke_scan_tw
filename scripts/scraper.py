import requests
from bs4 import BeautifulSoup
import json
import time
import os
import re
import subprocess
from tcgdexsdk import TCGdex

# ==========================================
# 1. è¨­å®šå€
# ==========================================
SETS_DIR = '../assets/sets'     # å­˜æ”¾åˆ†é–‹ JSON çš„è³‡æ–™å¤¾
INDEX_FILE = '../assets/index.json' # ç´¢å¼•æª”æ¡ˆè·¯å¾‘

TARGET_URLS_DIR = 'target_urls.json' # ç›®æ¨™ç¶²å€æ¸…å–®

PROMO_CODES = [
    "SM-P",
    "S-P",
    "SV-P",
    "M-P"
]

# åˆå§‹åŒ– TCGdex
tcgdex = TCGdex("zh-tw")

def clean_text(text):
    if not text: return ""
    return text.strip().replace('\n', '')
    
def load_target_urls():
    if not os.path.exists(TARGET_URLS_DIR):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è¨­å®šæª” {TARGET_URLS_DIR}")
        return []
    
    try:
        with open(TARGET_URLS_DIR, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        print(f"âŒ è¨­å®šæª” JSON æ ¼å¼éŒ¯èª¤: {e}")
        return []

def run_scraper():
    TARGET_URLS = load_target_urls()
    if not TARGET_URLS:
        print("âŒ ç„¡æœ‰æ•ˆçš„ç›®æ¨™ç¶²å€ï¼Œçˆ¬èŸ²çµ‚æ­¢ã€‚")
        return

    print("ğŸš€ é–‹å§‹åŸ·è¡Œæ™ºæ…§çˆ¬èŸ²...")

    headers = {'User-Agent': 'Mozilla/5.0'}

    # 1. ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
    if not os.path.exists(SETS_DIR):
        os.makedirs(SETS_DIR)

    # 2. é–‹å§‹è¿´åœˆ
    for target in TARGET_URLS:
        set_code = target['code']
        set_name = target['name']

        # å®šç¾©è©²ç³»åˆ—çš„æª”æ¡ˆè·¯å¾‘
        set_file_path = os.path.join(SETS_DIR, f"{set_code}.json")

        if os.path.exists(set_file_path):
            # å˜—è©¦è®€å–ä¸€ä¸‹ï¼Œç¢ºä¿æª”æ¡ˆä¸æ˜¯ç©ºçš„æˆ–å£çš„
            try:
                with open(set_file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                
                # å¦‚æœè®€å–æˆåŠŸï¼Œä¸”è£¡é¢æœ‰è©²ç³»åˆ—çš„ keyï¼Œå°±è¦–ç‚ºå·²å­˜åœ¨
                if set_code in existing_data:
                    print(f"â© [{set_code}] å·²å­˜åœ¨ï¼Œè·³éã€‚")
                    continue
            except:
                # å¦‚æœè®€å–å¤±æ•— (ä¾‹å¦‚ JSON æ ¼å¼å£æ‰)ï¼Œå‰‡ä¸è·³éï¼Œé‡æ–°çˆ¬å–ä¿®å¾©
                print(f"âš ï¸ [{set_code}] æª”æ¡ˆå­˜åœ¨ä½†ææ¯€ï¼Œæº–å‚™é‡æ–°çˆ¬å–...")

        current_set_data = {}
        if os.path.exists(set_file_path):
            try:
                with open(set_file_path, 'r', encoding='utf-8') as f:
                    full_data = json.load(f)
                    if set_code in full_data:
                        current_set_data = full_data[set_code]
            except:
                pass 

        # åˆå§‹åŒ–è³‡æ–™çµæ§‹ (å¦‚æœæ˜¯æ–°æª”æ¡ˆ)
        if not current_set_data:
            current_set_data = {
                "name": set_name,
                "releaseDate": "2000-01-01", # é è¨­æ—¥æœŸï¼Œä¹‹å¾Œå¯ç”¨ add_date.py æ›´æ–°
                "cards": {}
            }

        print(f"ğŸ•·ï¸ æƒæç³»åˆ—: {set_name} ({set_code})...")
        try:
            resp = requests.get(target['url'], headers=headers, timeout=15)
            soup = BeautifulSoup(resp.text, 'html.parser')
            tables = soup.find_all('table', class_='roundy')
            processed_count = 0 # æ–°å¢æˆ–è£œåœ–çš„æ•¸é‡
            skipped_count = 0   # å·²å­˜åœ¨çš„æ•¸é‡
            
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) < 3: continue

                    try:
                        # æå–ç·¨è™Ÿ
                        num_text = clean_text(cols[0].text)
                        if not num_text or not num_text[0].isdigit():
                            continue

                        card_num = num_text

                        existing_card = current_set_data['cards'].get(card_num)
                        
                        # æƒ…æ³ 1: å¡ç‰‡å·²å­˜åœ¨  -> è·³é
                        if existing_card:
                            skipped_count += 1
                            continue
                        
                        # æƒ…æ³ 2: å¡ç‰‡ä¸å­˜åœ¨ (æ–°å¡!) -> å¾€ä¸‹åŸ·è¡Œ
                        if not existing_card:
                            print(f"   âœ¨ ç™¼ç¾æ–°å¡ç‰‡: {card_num}")

                        # æå–åç¨± (é †ä¾¿æ›´æ–°æ–‡å­—ï¼Œä»¥é˜²æ˜¯æ–°å¡)
                        name_text = "æœªçŸ¥"
                        if len(cols) >= 3:
                            name_text = clean_text(cols[1].text)

                        # ç‰¹ä¾‹è™•ç†: name_text ç‚º "25å‘¨å¹´æ”¶è—ç‰ˆ" çš„è³‡æ–™æ˜¯éŒ¯èª¤çš„ï¼Œè·³éä¸å­˜
                        if name_text == "25å‘¨å¹´æ”¶è—ç‰ˆ":
                            continue

                        # æå–ç¨€æœ‰åº¦
                        rarity_text = ""
                        if len(cols) >= 4:
                            rarity_text = clean_text(cols[2].text)

                        # å¦‚æœç·¨è™Ÿæ ¼å¼ç‚º "001/S-P"ã€"001/SV-P"ã€"001/M-P"ï¼Œå‰‡å°‡ç¨€æœ‰åº¦è¨­ç½®ç‚ºPROMO
                        if any(code in num_text for code in PROMO_CODES):
                            rarity_text = "PROMO"

                        image_url = ""
                        # 1. å˜—è©¦ä¿ç•™èˆŠåœ–ç‰‡
                        if existing_card and existing_card.get('image'):
                            image_url = existing_card.get('image')

                        # 4. æ›´æ–°/å¯«å…¥è³‡æ–™
                        # é€™è£¡ä½¿ç”¨ update ç¢ºä¿å¦‚æœåŸæœ¬æœ‰å…¶ä»–æ¬„ä½(å¦‚ note)ä¸æœƒè¢«æ´—æ‰
                        if card_num not in current_set_data['cards']:
                            current_set_data['cards'][card_num] = {}

                        current_set_data['cards'][card_num]['name'] = name_text
                        current_set_data['cards'][card_num]['rarity'] = rarity_text
                        
                        # åªæœ‰ç•¶çœŸçš„æŠ“åˆ°æ–°åœ–æ™‚æ‰æ›´æ–° imageï¼Œé¿å…æŠŠåŸæœ¬æ‰‹å‹•å¡«çš„è“‹æˆç©ºå­—ä¸²
                        if image_url:
                            current_set_data['cards'][card_num]['image'] = image_url
                        elif 'image' not in current_set_data['cards'][card_num]:
                            current_set_data['cards'][card_num]['image'] = ""

                        processed_count += 1
                    except Exception:
                        continue
            
            print(f"   ğŸ’¾ {set_code} è™•ç†å®Œç•¢ã€‚è·³é: {skipped_count} å¼µ, è™•ç†(æ–°å¢): {processed_count} å¼µ")

            output_data = {set_code: current_set_data}
            with open(set_file_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            # åªæœ‰åœ¨çœŸçš„æœ‰ç™¼é€å¤§é‡è«‹æ±‚æ™‚æ‰ç¡è¦º
            if processed_count > 5:
                time.sleep(1)
            else:
                time.sleep(0.1)

        except Exception as e:
            print(f"   âŒ {set_code} å¤±æ•—: {e}")

    # 3. å»ºç«‹ç´¢å¼•æª” (Index)
    print("ğŸ“‘ æ­£åœ¨æ›´æ–°ç´¢å¼•æª” index.json ...")
    actual_files = [f.replace('.json', '') for f in os.listdir(SETS_DIR) if f.endswith('.json')]
    actual_files.sort()

    with open(INDEX_FILE, 'w', encoding='utf-8') as f:
        json.dump(actual_files, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    start_time = time.time()

    run_scraper()

    print("\nğŸš¦ é–‹å§‹ç°¡é«”è½‰ç¹é«”...")
    subprocess.run(["python", "convert.py"], check=True)

    print("\nğŸš¦ é–‹å§‹è½‰æ›å°ç£ç¿»è­¯...")
    subprocess.run(["python", "fix_translation.py"], check=True)

    print("\nğŸš¦ åŠ å…¥æ“´å……åŒ…ç™¼å”®æ—¥æœŸ...")
    subprocess.run(["python", "add_date.py"], check=True)

    # print("\nğŸš¦ é–‹å§‹è£œåœ–...")
    # subprocess.run(["python", "image_patch.py"], check=True)
    
    elapsed_time = time.time() - start_time
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    print(f"â±ï¸ ç¸½å…±èŠ±è²» {elapsed_time:.2f} ç§’ã€‚")

    print("\nâœ… å…¨éƒ¨å®Œæˆï¼")